# DSC245_Project

 In todayâ€™s digital landscape, brands increasingly rely on online advertisement, making it crucial to measure the impact of ads to make informed marketing decisions. Traditional A/B testing is often utilized to assess ad effectiveness, yet it can be time-consuming and costly. This raises the following question: How can we infer the causal impact of online ads on customer reactions more efficiently, minimizing both time and sample size while preserving inference robustness?
 
 Using a dataset of user interactions with an interactive online ad versus a dummy ad, including user attributes, group affiliations, timestamps, and questionnaire responses, we apply a blend of causal inference techniques to enhance efficiency and precision. We first employ a standard A/B testing framework with Average Treatment Effect (ATE) estimation under an ignorability assumption to establish baseline ad effectiveness. To optimize sample size requirements, we incorporate the Covariate-Adjusted Pretesting (CUPED) variance reduction method, which leverages covariate information to improve estimation efficiency. Several approaches will assist the finding of appropriate covariates, including A/A test and propensity score matching (PSM). Finally, we apply sequential testing, enabling interim analysis and the potential for early experiment termination based on significant results.
 
 By combining these advanced techniques, our approach aims to create a more resourceefficient framework for evaluating online ad effectiveness, balancing rigor with practicality  to yield actionable insights faster and with fewer resources
